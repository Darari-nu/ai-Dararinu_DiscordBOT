#!/usr/bin/env python3
"""
ğŸ™Œ è¦ç´„æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸè¨˜äº‹è¦ç´„æ©Ÿèƒ½ã®å‹•ä½œç¢ºèªç”¨
"""

import asyncio
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from utils.article_extractor import article_extractor

async def test_url_extraction():
    """URLæŠ½å‡ºæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== URLæŠ½å‡ºãƒ†ã‚¹ãƒˆ ===")
    
    test_texts = [
        "ã“ã‚Œã¯è¨˜äº‹ã§ã™: https://example.com/article/1",
        "è¤‡æ•°URL: https://example.com/1 ã¨ https://example.com/2",
        "URLãªã—ã®ãƒ†ã‚­ã‚¹ãƒˆ",
        "https://github.com/example/repo",
        "Discord URL: https://discord.com/channels/123/456/789"
    ]
    
    for text in test_texts:
        urls = article_extractor.extract_urls_from_text(text)
        print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
        print(f"æŠ½å‡ºURL: {urls}")
        print("-" * 40)

async def test_article_fetch():
    """è¨˜äº‹å–å¾—æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆï¼ˆå¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ãªã—ï¼‰"""
    print("\n=== è¨˜äº‹å–å¾—ãƒ†ã‚¹ãƒˆ ===")
    
    # ç„¡åŠ¹ãªURLã®ãƒ†ã‚¹ãƒˆ
    invalid_urls = [
        "http://invalid-url-12345.com",
        "https://localhost:8080/test",
        "not-a-url",
        "https://999.999.999.999",
    ]
    
    for url in invalid_urls:
        print(f"ãƒ†ã‚¹ãƒˆURL: {url}")
        is_valid = article_extractor._is_valid_url(url)
        print(f"æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯: {is_valid}")
        print("-" * 40)

def test_prompt_loading():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ ===")
    
    prompt_path = Path(__file__).parent / "prompt" / "summary.txt"
    
    if prompt_path.exists():
        with open(prompt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {prompt_path}")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(content)} æ–‡å­—")
        print(f"å…ˆé ­200æ–‡å­—: {content[:200]}...")
        print("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
    else:
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_path}")

def test_settings_file():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª"""
    print("\n=== è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ ===")
    
    import json
    settings_path = Path(__file__).parent / "settings.json"
    
    if settings_path.exists():
        with open(settings_path, 'r', encoding='utf-8') as f:
            settings = json.load(f)
        
        print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {settings_path}")
        print(f"è¨­å®šå†…å®¹: {json.dumps(settings, indent=2, ensure_ascii=False)}")
        
        # summary_daily_limitã®ç¢ºèª
        if 'summary_daily_limit' in settings:
            print("âœ… summary_daily_limit ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
        else:
            print("âŒ summary_daily_limit ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    else:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {settings_path}")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ™Œ è¦ç´„æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    await test_url_extraction()
    await test_article_fetch()
    test_prompt_loading()
    test_settings_file()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    print("\nğŸ“‹ å®Ÿè£…ç¢ºèªé …ç›®:")
    print("âœ… prompt/summary.txt ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")
    print("âœ… utils/article_extractor.py ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½œæˆ")
    print("âœ… main.py ã«ğŸ™Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³å‡¦ç†è¿½åŠ ")
    print("âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã‚³ãƒãƒ³ãƒ‰è¿½åŠ ")
    print("âœ… ãƒ˜ãƒ«ãƒ—ã‚³ãƒãƒ³ãƒ‰æ›´æ–°")
    print("âœ… requirements.txt æ›´æ–°ï¼ˆbeautifulsoup4, readability-lxmlï¼‰")
    print("âœ… settings.json æ›´æ–°ï¼ˆsummary_daily_limitè¿½åŠ ï¼‰")
    
    print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. pip install beautifulsoup4 readability-lxml")
    print("2. Discordã‚µãƒ¼ãƒãƒ¼ã§ãƒ†ã‚¹ãƒˆ")
    print("3. å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹URLã§å‹•ä½œç¢ºèª")

if __name__ == "__main__":
    asyncio.run(main())